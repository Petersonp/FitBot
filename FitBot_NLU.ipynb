{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Petersonp/FitBot/blob/main/FitBot_NLU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6fukBOF4bUn"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install rouge_score\n",
        "!pip install accelerate==0.20.1\n",
        "!pip install transformers[torch] -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_eO8OB642iI"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVMWC1ALDJ0i",
        "outputId": "622939a8-85f4-41c2-85bf-26837ad9cb61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHYxD-imBo1t",
        "outputId": "e8c8724c-4911-4234-8a65-917c3fb96000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  text                label\n",
            "0       How many calories should I eat to lose weight?  CreateNutritionPlan\n",
            "1              What should my daily protein intake be?  CreateNutritionPlan\n",
            "2    What's my target calorie intake if I want to g...  CreateNutritionPlan\n",
            "3    Plan my macros for a weight loss goal of 10 po...  CreateNutritionPlan\n",
            "4      Need a diet plan that fits 3000 daily calories.  CreateNutritionPlan\n",
            "..                                                 ...                  ...\n",
            "410           Give me an exercise that targets biceps.    RecommendExercise\n",
            "411       Suggest an exercise for improving endurance.    RecommendExercise\n",
            "412        What are some exercises for a flat stomach?    RecommendExercise\n",
            "413  Recommend a beginner-friendly exercise for wei...    RecommendExercise\n",
            "414  Show me an exercise to increase upper body str...    RecommendExercise\n",
            "\n",
            "[415 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/23-24/CS 4701/intent.csv')\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.1)\n",
        "\n",
        "# You would also want to process your labels if they are not already in numeric form\n",
        "# For example, mapping 'GetNutritionInfo' to 0, 'CreateWorkoutPlan' to 1, etc.\n",
        "label_to_id = {label: i for i, label in enumerate(df['label'].unique())}\n",
        "id_to_label = {i: label for label, i in label_to_id.items()}\n",
        "num_intents = len(label_to_id)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(id_to_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4vxsPiSMzXN",
        "outputId": "16919798-8ed1-4b23-cd6c-b1e59b5b255c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'CreateNutritionPlan', 1: 'CreateWorkoutPlan', 2: 'RecommendMeal', 3: 'RecommendExercise', 4: 'QueryFood', 5: 'QueryExercise', 6: 'Unrelated'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-48XeE1rBURF"
      },
      "outputs": [],
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the text\n",
        "train_encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(val_df['text'].tolist(), truncation=True, padding=True, max_length=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJMYnlaBD_36"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Convert the labels to numeric form\n",
        "train_labels = train_df['label'].map(label_to_id).tolist()\n",
        "val_labels = val_df['label'].map(label_to_id).tolist()\n",
        "\n",
        "# Create the dataset objects\n",
        "train_dataset = CustomDataset(train_encodings, train_labels)\n",
        "val_dataset = CustomDataset(val_encodings, val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MURVnI7UECIJ",
        "outputId": "4886f8a6-763c-4efa-8ff1-8ac3da109e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load a pre-trained model for sequence classification with the number of labels in your dataset\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_to_id))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETK7GQ1DEVwx"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # where to save model checkpoints\n",
        "    num_train_epochs=17,              # number of epochs\n",
        "    per_device_train_batch_size=32,  # batch size for training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps\n",
        "    weight_decay=0.01,               # weight decay rate\n",
        "    evaluation_strategy='epoch',     # evaluate after each epoch\n",
        "    logging_dir='./logs',            # where to store logs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "YfYdcBeqEIOT",
        "outputId": "f13ad9a7-5378-4e1c-c5b3-04600e88ddbe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [204/204 00:31, Epoch 17/17]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.002736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.926759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.844813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.808089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.768617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.710552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.600455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.468989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.285760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.085180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.905802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.746537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.593437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.508588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.419220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.430302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.574651</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=204, training_loss=1.171887341667624, metrics={'train_runtime': 31.2622, 'train_samples_per_second': 202.832, 'train_steps_per_second': 6.525, 'total_flos': 68433015857850.0, 'train_loss': 1.171887341667624, 'epoch': 17.0})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "nZ2iLcyqGEhB",
        "outputId": "4e4ab5d7-5403-40e4-f116-4885694f9c59"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5746512413024902,\n",
              " 'eval_runtime': 0.0566,\n",
              " 'eval_samples_per_second': 741.417,\n",
              " 'eval_steps_per_second': 17.653,\n",
              " 'epoch': 17.0}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "trainer.evaluate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhuKHdYPGrqT",
        "outputId": "440c8137-0c63-416c-dadc-cfa0e1dca93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: how many calories in 2 lb of chicken\n",
            "Predicted intent: QueryFood\n"
          ]
        }
      ],
      "source": [
        "# Assuming that CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the device\n",
        "model.to(device)\n",
        "# Example text\n",
        "test_text = \"how many calories in 2 lb of chicken\"\n",
        "\n",
        "# Encode the text and move the inputs to the same device as the model\n",
        "inputs = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "\n",
        "# Now the rest of your code should work without device mismatch\n",
        "\n",
        "\n",
        "# Get predictions\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Extract the logits\n",
        "logits = outputs.logits\n",
        "\n",
        "# Convert logits to probabilities\n",
        "probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "# Get the predicted label\n",
        "predicted_label_id = torch.argmax(probabilities, dim=-1).item()\n",
        "predicted_label = id_to_label[predicted_label_id]\n",
        "\n",
        "print(f\"Input: {test_text}\")\n",
        "print(f\"Predicted intent: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sirxEJpZKbzK",
        "outputId": "98520b54-2cf2-42af-e31b-ce374707de39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/23-24/CS 4701/Intent Trained Model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/23-24/CS 4701/Intent Trained Model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/23-24/CS 4701/Intent Trained Model/vocab.txt',\n",
              " '/content/drive/MyDrive/23-24/CS 4701/Intent Trained Model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Save the model and tokenizer to disk\n",
        "\n",
        "model.save_pretrained('/content/drive/MyDrive/23-24/CS 4701/Intent Trained Model')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/23-24/CS 4701/Intent Trained Model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOe584m3IG-V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}